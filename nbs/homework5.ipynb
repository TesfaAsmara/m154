{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ff7059",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "> Subject sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb31b2",
   "metadata": {},
   "source": [
    "\n",
    "1. Finish the algorithm from Lab 2.  The code provided in class that is under Resources > Lectures presents the estimate after a fixed number of iterations.  Instead, have it return the estimate that has the smallest SSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3db24",
   "metadata": {},
   "source": [
    "Lab 2 was about Boosting. Here is a boosting method. It scored 95.5% on a random dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900b9b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 1000, n_features = 10,n_informative = 2, n_redundant = 0,random_state = 0, shuffle = False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =1234)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ed514",
   "metadata": {},
   "source": [
    "2. Why is the smallest SSE not attained by the last iteration?  It certainly is created with the most knots and thus in some sense the most flexible.  Why does the algorithm not converge? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914d6d8",
   "metadata": {},
   "source": [
    "I am not sure what \"last iteration\" this question is asking about; I think it is related to the question 1 and this line in lab 2: \"Pick the estimator that has the lowest sum of squares (a terrible idea if we thought that this might eventually fit noise).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e2594",
   "metadata": {},
   "source": [
    "3. Why are we able to simply minimize SSE (not regularize, or need to hide data from the learner in a CV routine)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177ccb7",
   "metadata": {},
   "source": [
    "We are able to simply minimize SSE because least squares has lots of nice properties and it is useful for estimating means at the undergraduate level. Boosting with weak learners also prevents overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7134f9c",
   "metadata": {},
   "source": [
    "4. Why does the smoothness vary across the unit interval when we only selected a single smoothing parameter (who's value, if we were doing traditional kernel smoothing, would seemingly play connect-the-dots)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99cd71",
   "metadata": {},
   "source": [
    "The larger the smooth width, the greater the noise reduction, but also the greater the possibility that the signal will be distorted by the smoothing operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ba2f3",
   "metadata": {},
   "source": [
    "5. Run the learner on another simulated data set.  Again, let the input be a grid (you'd need to change the code a lot to run this on unequally spaced data).  What is the critical parameter that needs to be choosen for the method to work well?  Can you interpret it?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a3eb6",
   "metadata": {},
   "source": [
    "The critical parameter that needs to be choosen for the method to work well is the minimum spacing between knots. No, I cannot interpret it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:m154] *",
   "language": "python",
   "name": "conda-env-m154-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
