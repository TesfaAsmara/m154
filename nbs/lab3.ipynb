{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f973f4a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"154 - Lecture 20 / Lab 3\"\n",
    "author: \"Gabe\"\n",
    "date: \"10/29/2020\"\n",
    "output: pdf_document\n",
    "---\n",
    "\n",
    "```{r setup, include=FALSE}\n",
    "require(randomForest)\n",
    "require(e1071)\n",
    "require(rpart)\n",
    "```\n",
    "\n",
    "# Random Forests\n",
    "\n",
    "The number of possible trees that could be produced is massive (on the first split there are $p(n-1)$ choices we consider).  Thinking multiple steps ahead to lessen the issues of using a greedy algorithm will increase the computational complexity exponentially.   \n",
    "\n",
    "Instead, we grow many trees (which means we can parallelize it!).  The space of possible trees is still too massive to really explore in any meaningful sense, and it's so big that taking \"bad\" moves sometimes is unlikely to be helpful (some \"bad\" moves lead to \"great\" partitions, but given the size of the space, most \"bad\" moves probably result in \"bad\" partitions).  So, we'll still use a greedy algorithm and always make the \"best\" moves, we'll just limit the moves available.  \n",
    "\n",
    "So we will give it only a subset (*mtry*) of the predictor variables on which to split (different each iteration).  The other tuning parameters are the maximum number of nodes (*maxnodes*), and the smallest allowable node size (*nodesize*), which are clearly related. They limit the size of the tree that is grown, which can control computation time.  The defaults are no limit on the number of nodes, and the smallest node size is 1, i.e. grow the biggest trees possible (so that every terminal node consists of a single observation).  This is not the obvious problem that it would be in CART, which would feel like a 1-NN classifier.  Instead, predicting a new observation by pushing it down each tree in the ensemble will result in different partitions, that, while only consisting of a single observation, will often be a collection of different observations for each tree.  But we can play around and try to optimize the choice of *nodesize* or *maxnodes* via cross-validation. \n",
    "\n",
    "Additionally, we'll also give it a different data set each time, but a data set that *looks* like the real data.  A bootstrap sample! So called *bagging*. \n",
    "\n",
    "There's some fun stuff we'll get from this.  A good estimate of misclassification rate (using majority vote) or sum of squared errors in the regression case is free because we have grown trees that haven't seen some of our data (*out-of-bag* observations).  Built in cross-validation!  \n",
    "\n",
    "Additionally, since on every step we are doing a univariate analysis, we can discuss which variables seem to be useful. \n",
    "\n",
    "## Interpreting \n",
    "\n",
    "We can rank the value of the variables in our data set in terms of the **variable importance**.  There are a couple of ways we can do this.  We can see how much Gini Impurity decreases on average when the variable is chosen to split on. \n",
    "\n",
    "Alternatively, we can scramble the values of a variable, push every observation down the trees for which it is out-of-bag, and see how much worse classification (majority vote) gets. This is *accuracy-based importance*, while the average Gini decrease is what should be returned by *randomForest*.  \n",
    "\n",
    "A nice feature of random forests is that it is affine invariant, the results will not depend whether or not you scaled your data (as opposed to SVM, as the geometric margin of a data set depends on the choice of units). \n",
    "\n",
    "# Lab 3\n",
    "\n",
    "Generate some data with $p=2$ (not wheelhouse for RF but I\n",
    "want to visualize). Do so such that you can find the decision boundary coming from the Bayes classifier. Optimize your learners via cross-validation, and using the *plot.learner* function, visualize the resulting decision boundary and discuss. \n",
    "\n",
    "\n",
    "```{r}\n",
    "plot.learner <- function(fit, x1LB, x1UB, x2LB, x2UB, data) {\n",
    "  #Plots \"preimage\" of linear decision boundary generated in 3 space by added basis function\n",
    "  #\n",
    "  #Inputs\n",
    "  #  fit: svm object\n",
    "  #  x1LB, x1UB: lower and upper bounds for variable x1\n",
    "  #  x2LB, x2UB: lower and upper bounds for variable x2\n",
    "  #  data: data frame containing variables, need to have variables named y, x1 and x2\n",
    "  x1.grid <- seq(x1LB, x1UB, length.out=100)\n",
    "  x2.grid <- seq(x2LB, x2UB, length.out=100)\n",
    "  data.pred <- c()\n",
    "  for (i in 1:length(x1.grid)) {\n",
    "    for (j in 1:length(x2.grid)) {\n",
    "      data.pred <- rbind(data.pred, c(x1.grid[i], x2.grid[j]))\n",
    "    }\n",
    "  }\n",
    "  data.pred <- as.data.frame(data.pred)\n",
    "  names(data.pred) <- c('x1', 'x2')\n",
    "\n",
    "  plot(data$x1,data$x2,col=as.numeric(data$y)+8)\n",
    "  points(data.pred[,1:2],col=as.numeric(predict(fit, newdata=data.pred))+2, cex=.4, pch=19)\n",
    "  points(data$x1,data$x2,col=as.numeric(data$y)+8, pch=19)\n",
    "}\n",
    "```\n",
    "\n",
    "```{r}\n",
    "x1 <- runif(100)\n",
    "x2 <- runif(100)\n",
    "y <- 1 * (x1 < x2)\n",
    "flip <- sample(100,10)\n",
    "y[flip] <- -y[flip]+1  #add a little noise to the problem\n",
    "y <- as.factor(y)\n",
    "plot(x1,x2,col=as.numeric(y)+1, pch=19)\n",
    "abline(0,1) #bayes classifier\n",
    "```\n",
    "\n",
    "*plot.learner* should work for randomForest and svm.  rpart returns class proportions instead of classifications, and needs a hack:\n",
    "\n",
    "\n",
    "```{r}\n",
    "plot.learner.rpart <- function(fit, x1LB, x1UB, x2LB, x2UB, data) {\n",
    "  #Plots preimage of linear decision boundary generated in 3 space by added basis function\n",
    "  #\n",
    "  #Inputs\n",
    "  #  fit: svm object\n",
    "  #  x1LB, x1UB: lower and upper bounds for variable x1\n",
    "  #  x2LB, x2UB: lower and upper bounds for variable x2\n",
    "  #  data: data frame containing variables, need to have variables named y, x1 and x2\n",
    "  x1.grid <- seq(x1LB, x1UB, length.out=100)\n",
    "  x2.grid <- seq(x2LB, x2UB, length.out=100)\n",
    "  data.pred <- c()\n",
    "  for (i in 1:length(x1.grid)) {\n",
    "    for (j in 1:length(x2.grid)) {\n",
    "      data.pred <- rbind(data.pred, c(x1.grid[i], x2.grid[j]))\n",
    "    }\n",
    "  }\n",
    "  data.pred <- as.data.frame(data.pred)\n",
    "  names(data.pred) <- c('x1', 'x2')\n",
    "\n",
    "  plot(data$x1,data$x2,col=as.numeric(data$y)+8)\n",
    "  points(data.pred[,1:2],col=round(predict(fit, newdata=data.pred))[,1]+2, cex=.2, pch=19)\n",
    "  points(data$x1,data$x2,col=as.numeric(data$y)+8, pch=19)\n",
    "}\n",
    "```\n",
    "\n",
    "```{r}\n",
    "data.1 <- data.frame(y,x1,x2)\n",
    "fit.rpart <- rpart(y~., data=data.1)\n",
    "plot.learner.rpart(fit.rpart,0,1,0,1,data.1)\n",
    "```\n",
    "To appreciate variable importance, we can try to predict the transmission type of a car from the *mtcars* dataframe. \n",
    "\n",
    "```{r, include=FALSE}\n",
    "require(randomForest)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "data(mtcars)\n",
    "mtcars$am <- as.factor(mtcars$am)\n",
    "fit <- randomForest(am~., data=mtcars)\n",
    "fit \n",
    "fit$importance\n",
    "```\n",
    "\n",
    "Have a look for the classification problem you explored in the most recent homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:m154] *",
   "language": "python",
   "name": "conda-env-m154-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
