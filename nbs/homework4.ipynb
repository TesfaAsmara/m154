{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d951d5",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "> Subject sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45c823",
   "metadata": {},
   "source": [
    "1.  a. Show that the level sets (the collection of values of $\\beta_1$ and $\\beta_2$ such that $Q(B):=\\sum(y_i-\\beta_1x_{1i} - \\beta_2 x_{2i})^2=k$) are in fact ellipses as claimed in class.  According to  https://www.maa.org/external_archive/joma/Volume8/Kalman/General.html, \"the general equation for a rotated ellipse centered at $(h, k)$ has the form $A(x - h)^2 + B(x - h)(y - k) + C(y - k)^2 = 1$, again where $A$ and $C$ are positive, and $B^2 - 4AC < 0$\" and that a rotated ellipse has a non-zero $xy$ term.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e5864",
   "metadata": {},
   "source": [
    "By completing the square of $\\sum(y_i - \\beta_1x_{1i} - \\beta_2x_{2i})$, we will find that it takes on the general equation for a rotated ellipse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf915986",
   "metadata": {},
   "source": [
    "b. State what would have to be true about the data in order for this to be a standard ellipse (major and minor axes aligned with coordinate axis) (see the coefficient of the $xy$ term in equation 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3ea2a",
   "metadata": {},
   "source": [
    "If the ellipse has standard axes, then the predictor variables have to be ortogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280deefe",
   "metadata": {},
   "source": [
    "2. a. We drew the $l_1$ ball in 2 dimensions ($\\{(x_1, x_2):|x_1| + |x_2|\\leq k\\}$)  in class, and showed that it has 4 corners.  State and argue how many corners the $l_1$ ball in 3 dimensions has.  Describe the regions of the boundary that give you ``sparse\" (not all $\\hat{\\beta}_i\\neq 0$) solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0292d26",
   "metadata": {},
   "source": [
    "The regions of the boundary that give you sparse solutions are the 6 corners $(k,0,0),(−k,0,0),(0,k,0),(0,−k,0),(0,0,k),(0,0,−k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee0022",
   "metadata": {},
   "source": [
    "b.  Compute the ratio of the radius of the inscribed $l_2$ ball  to the circumscribed $l_2$ ball of the $l_1$-unit ball ($k=1$) as  a function of the dimension $d$ and show that it is heading to 0 as $d\\to\\infty$.  (Hint:  What is the value closest to the origin in Euclidean distance.  Check the 2-$d$ plot to infer the general solution).  Note that the corners of the $d$-ball, which give the sparsest solution, live on the circumscribed ball, while the non-sparse solution (all $d$ $\\hat{\\beta}$ are non-zero) lives on a hyper-plane that touches the inscribed ball. \n",
    "\n",
    "Here's the picture in 2-$d$.\n",
    "```{r}\n",
    "plot(c(-1,1), c(-1,1), t='n', asp=1)\n",
    "lines(c(-1,0,1,0,-1),c(0,1,0,-1,0))\n",
    "a <- seq(0,2*pi,.01)\n",
    "r1 <- 1\n",
    "r2 <- sqrt(2)/2\n",
    "lines(r1*cos(a), r1*sin(a), col='red')\n",
    "lines(r2*cos(a), r2*sin(a), col='blue')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d03c16",
   "metadata": {},
   "source": [
    "The ratio of the radius of the inscribed $l_2$ ball to the circumscribed $l_2$ ball of the $l_1$-unit ball as a function of the dimension $d$ is $\\frac{1}{\\sqrt{d}}$, which is going to $0$ as $d \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed0499",
   "metadata": {},
   "source": [
    "3.  Write a function that computes a ridge regression and returns the fitted values.  Fitted values will be of the form $X\\hat{B}$ where $\\hat{B}=(X^TX+\\lambda I)^{-1}X^TY$, where $X$ is a matrix who's columns are the basis vectors of the subspace we are projecting onto, i.e. a vector of all ones, and the data vectors.\n",
    "\n",
    "The function will take in a vector of the response variable $y$, a matrix of predictors (without the intercept), and a value of $\\lambda$. \n",
    "\n",
    "Here's ordinary least squares to see how to work with matricies in R. \n",
    "\n",
    "```{r}\n",
    "set.seed(47)\n",
    "n <- 10\n",
    "x <- runif(n)\n",
    "y <- 3 + 5 * x + rnorm(n, 0, 1)\n",
    "plot(x,y)\n",
    "a <- rep(1,n)\n",
    "X <- cbind(a,x) #create the design matrix\n",
    "beta <- solve(t(X) %*% X) %*% t(X) %*% y #matrix multiplication in R and transpose of a matrix\n",
    "abline(beta, col='red')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a2b96",
   "metadata": {},
   "source": [
    "The scikit-learn Python machine learning library provides an implementation of the Ridge Regression algorithm via the Ridge class. The lambda term can be configured via the “alpha” argument.\n",
    "\n",
    "Given a response variable $y$, a matrix of predictors (without the intercept) $X$, and a value of $\\lambda$, the following python code will compute a ridge regress, return the fitted values, and will even evaluate the model!\n",
    "\n",
    "```{python}\n",
    "# evaluate an ridge regression model on the dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "# Here we are defining out ridge regression model\n",
    "model = Ridge(alpha=1.0)\n",
    "# Here we are defining a model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# Here we are evaluating the model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# Here we force the scores to be positive and print\n",
    "scores = np.absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ea9c0",
   "metadata": {},
   "source": [
    "4. Using the *mtcars* data set as we did in Lecture 8 (removing mpg and qsec to form the matrix of predictors), build a model for fuel efficiency using a combination of feature engineering (non-linear transformations of existing variables) and the LASSO. See the notes and the vignette linked therein for using the glmnet package. \n",
    "\n",
    "```{r}\n",
    "data(mtcars)\n",
    "y <- mtcars$mpg\n",
    "x <- as.matrix(mtcars[,-c(1,7)])\n",
    "x <- cbind(x, x[,3]^2) #add hp^2 to the data set.  \n",
    "x <- cbind(x, x[,3] * x[,4]) #add hp * drat to the data set\n",
    "```\n",
    "\n",
    "Note: this seems clunky, but with simple features, we are likely to have a model that allows some interpretability (as opposed to adding infinitely many features, which we will do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72df8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.Lasso(alpha = 0.5)\n",
    "\n",
    "# Import CSV mtcars\n",
    "mtcars = pd.read_csv('https://gist.githubusercontent.com/ZeccaLehn/4e06d2575eb9589dbe8c365d61cb056c/raw/64f1660f38ef523b2a1a13be77b002b98665cdfe/mtcars.csv')\n",
    "# Edit element of column header\n",
    "mtcars.rename(columns={'Unnamed: 0':'brand'}, inplace=True)\n",
    "y = mtcars['mpg']\n",
    "X = mtcars.drop(columns=['brand','mpg', 'qsec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c407f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients of our model are [-0.13286461 -0.02288867 -0.01944688  0.         -0.99519437  0.\n",
      "  0.          0.         -0.21000753]\n",
      "The intercept of our model is 32.83869012090861\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "print(f'The coefficients of our model are {clf.coef_}')\n",
    "print(f'The intercept of our model is {clf.intercept_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:m154] *",
   "language": "python",
   "name": "conda-env-m154-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
